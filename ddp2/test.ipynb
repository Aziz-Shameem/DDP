{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from abc import abstractmethod\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import rand\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "fid = FrechetInceptionDistance(feature=64)\n",
    "# generate two slightly overlapping image intensity distributions\n",
    "imgs_dist1 = torch.randint(0, 200, (100, 3, 28, 28), dtype=torch.uint8)\n",
    "imgs_dist2 = torch.randint(100, 255, (100, 3, 28, 28), dtype=torch.uint8)\n",
    "fid.update(imgs_dist1, real=True)\n",
    "fid.update(imgs_dist2, real=False)\n",
    "f = fid.compute()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (utils.py, line 406)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\n\u001b[1;33m    from utils import *\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:406\u001b[1;36m\u001b[0m\n\u001b[1;33m    nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "model = UNetModel(\n",
    "    in_channels=3,\n",
    "    model_channels=96,\n",
    "    out_channels=3,\n",
    "    channel_mult=(1, 2, 2),\n",
    "    attention_resolutions=[]\n",
    ")\n",
    "nparams, fid, losslog, imgs, model = run(model, name='test', dataset_name='cifar10', epochs=1, batchsize=64, timesteps=5, device='cpu', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cpu\n",
      "0 cpu\n",
      "1 cpu\n",
      "1 cpu\n",
      "2 cpu\n",
      "2 cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n",
      "hs cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UnetDWT2()\n",
    "inp = torch.randn(10,3,32,32)\n",
    "op = model(inp, torch.randn(10))\n",
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 64\n",
    "timesteps = 500\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
    "])\n",
    "\n",
    "# use MNIST dataset\n",
    "dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# define model and diffusion\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'{device=}')\n",
    "model = UNetModel(\n",
    "    in_channels=1,\n",
    "    model_channels=96,\n",
    "    out_channels=1,\n",
    "    channel_mult=(1, 2, 2),\n",
    "    attention_resolutions=[]\n",
    ")\n",
    "# model = WaveMixSR(\n",
    "#     depth = 4,\n",
    "#     mult = 1,\n",
    "#     ff_channel = 144,\n",
    "#     final_dim = 144,\n",
    "#     dropout = 0.3\n",
    "# )\n",
    "model.to(device)\n",
    "\n",
    "gaussian_diffusion = GaussianDiffusion(timesteps=timesteps)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "print(sum([p.numel() for p in model.parameters()])/10**6, ' M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 96, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Level1Waveblock( mult = 1,\n",
    " ff_channel = 16,\n",
    " final_dim = 96)\n",
    "inp = torch.randn(10,96,32,32)\n",
    "op = a(inp)\n",
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[:500].transpose((0,3,1,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38056"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in a.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37152"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = AttentionBlock(channels=96)\n",
    "sum([p.numel() for p in b.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step:   1%|‚ñè         | 7/500 [01:22<1:36:23, 11.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m i1 \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdata[:corpus]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i1\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m : i1 \u001b[38;5;241m=\u001b[39m i1\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m gen_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_diffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m i2 \u001b[38;5;241m=\u001b[39m gen_imgs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[0;32m      8\u001b[0m i2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(i2)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:858\u001b[0m, in \u001b[0;36mGaussianDiffusion.sample\u001b[1;34m(self, model, image_size, batch_size, channels)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, image_size, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m--> 858\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:851\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample_loop\u001b[1;34m(self, model, shape)\u001b[0m\n\u001b[0;32m    849\u001b[0m imgs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimesteps)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling loop time step\u001b[39m\u001b[38;5;124m'\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimesteps):\n\u001b[1;32m--> 851\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m     imgs\u001b[38;5;241m.\u001b[39mappend(img\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imgs\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:833\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample\u001b[1;34m(self, model, x_t, t, clip_denoised)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, x_t, t, clip_denoised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;66;03m# predict mean and variance\u001b[39;00m\n\u001b[1;32m--> 833\u001b[0m     model_mean, _, model_log_variance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_t)\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;66;03m# no noise when t == 0\u001b[39;00m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:820\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[1;34m(self, model, x_t, t, clip_denoised)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, x_t, t, clip_denoised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;66;03m# predict noise using model\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     pred_noise \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# get the predicted x_0: different from the algorithm2 in the paper\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_start_from_noise(x_t, t, pred_noise)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:613\u001b[0m, in \u001b[0;36mUNetModel.forward\u001b[1;34m(self, x, timesteps)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_blocks:\n\u001b[0;32m    612\u001b[0m     cat_in \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h, hs\u001b[38;5;241m.\u001b[39mpop()], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 613\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(h)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:349\u001b[0m, in \u001b[0;36mTimestepEmbedSequential.forward\u001b[1;34m(self, x, emb)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, TimestepBlock):\n\u001b[1;32m--> 349\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\papers\\DDP\\ddp2\\utils.py:391\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[0;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    `x` has shape `[batch_size, in_dim, height, width]`\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    `t` has shape `[batch_size, time_dim]`\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Add time step embeddings\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     h \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb(t)[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "gaussian_diffusion = GaussianDiffusion(timesteps=500)\n",
    "corpus = 500\n",
    "i1 = dataset.data[:corpus]\n",
    "if i1.dim()==3 : i1 = i1.unsqueeze(1)\n",
    "gen_imgs = gaussian_diffusion.sample(model, 28, batch_size=corpus, channels=1)\n",
    "i2 = gen_imgs[-1].reshape(-1, 1, 28, 28)\n",
    "i2 = torch.tensor(i2)\n",
    "fid = calculate_fid(i1, i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedSet([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedSet([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a.add(4)\n",
    "a.add(0)\n",
    "a.add(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def _idwt1d(\n",
    "    lo: torch.Tensor, hi: torch.Tensor, lo_hi: torch.Tensor, dim: int = -1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"performs a 1d idwt on the defined dimension\n",
    "\n",
    "    Args:\n",
    "        lo (torch.Tensor): 5d low (average) coefs of shape [N,C,D,H,W]\n",
    "        hi (torch.Tensor): 5d hi (detail) coefs of shape [N,C,D,H,W]\n",
    "        lo_hi (torch.Tensor): lo,hi pass filters of shape [2,K]\n",
    "        dim (int, optional): dimension to apply the idwt to . Defaults to -1.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: reconstructed tensor of shape [N,C,D_out,H_out,W_out] (e.g. H_out = 2*H if dim==-1)\n",
    "    \"\"\"\n",
    "    dim = dim % 5\n",
    "\n",
    "    groups = lo.shape[1]\n",
    "    filter_c = (\n",
    "        lo_hi[:, None, None, None, None, :]\n",
    "        .repeat(1, groups, 1, 1, 1, 1)\n",
    "        .swapaxes(5, dim + 1)  # swap filter to dwt dim\n",
    "    )\n",
    "\n",
    "    # stride of 2 for dwt dim\n",
    "    stride = [1, 1, 1]\n",
    "    stride[dim - 2] = 2\n",
    "    padding = [0, 0, 0]\n",
    "    padding[dim - 2] = lo_hi.shape[-1] - 2\n",
    "\n",
    "    a_coefs = F.conv_transpose3d(\n",
    "        lo, filter_c[0], stride=stride, padding=padding, groups=groups\n",
    "    )\n",
    "    d_coefs = F.conv_transpose3d(\n",
    "        hi, filter_c[1], stride=stride, padding=padding, groups=groups\n",
    "    )\n",
    "    return a_coefs + d_coefs\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _dwt1d(x: torch.Tensor, lo_hi: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
    "    \"\"\"performs a 1d dwt on the defined dimension\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): 4d tensor of shape [N,C,D,H,W]\n",
    "        lo_hi (torch.Tensor): low and highpass filter (shape [2,K])\n",
    "        dim (int, optional): dimension to apply the dwt to . Defaults to -1.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: dwt coefs of shape [N,2,C,D_out,H_out,W_out]. The average and detail coefs are concatenated in the channels\n",
    "    \"\"\"\n",
    "    dim = dim % 5\n",
    "    groups = x.shape[1]\n",
    "    # repeat filter to match number of channels\n",
    "    filter_c = lo_hi[:, None, None, None, :].repeat(groups, 1, 1, 1, 1).swapaxes(4, dim)\n",
    "\n",
    "    if x.shape[dim] % 2 != 0:\n",
    "        # pad dwt dimension to multiple of two\n",
    "        pad = [0] * 6\n",
    "        pad[(4 - dim) * 2 + 1] = 1\n",
    "        x = F.pad(x, pad)\n",
    "\n",
    "    # stride of 2 for dwt dim\n",
    "    stride = [1, 1, 1]\n",
    "    stride[dim - 2] = 2\n",
    "\n",
    "    padding = [0, 0, 0]\n",
    "    padding[dim - 2] = lo_hi.shape[-1] - 2\n",
    "\n",
    "    filtered = F.conv3d(x, filter_c, stride=stride, padding=padding, groups=groups)\n",
    "    return filtered.reshape(\n",
    "        filtered.shape[0],\n",
    "        groups,\n",
    "        2,\n",
    "        filtered.shape[2],\n",
    "        filtered.shape[3],\n",
    "        filtered.shape[4],\n",
    "    ).swapaxes(1, 2)\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _dwt2(x: torch.Tensor, lohi: torch.Tensor) -> torch.Tensor:\n",
    "    lh = _dwt1d(x[:, :, None, :, :], lohi, -1)\n",
    "    y = _dwt1d(lh.flatten(1, 2), lohi, -2).squeeze(-3)\n",
    "\n",
    "    # reorder coefs to match pywt ordering\n",
    "    return y.reshape(x.shape[0], 4, x.shape[1], y.shape[-2], y.shape[-1])\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _idwt2(x: torch.Tensor, lohi: torch.Tensor) -> torch.Tensor:\n",
    "    ll, hl, lh, hh = x.swapaxes(1, 2).unsqueeze(-3).unbind(2)\n",
    "\n",
    "    lo = _idwt1d(ll, lh, lohi, dim=-2)\n",
    "\n",
    "    hi = _idwt1d(hl, hh, lohi, dim=-2)\n",
    "    y = _idwt1d(lo, hi, lohi, dim=-1)\n",
    "    return y.squeeze(-3)\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _dwt3(x: torch.Tensor, lohi: torch.Tensor) -> torch.Tensor:\n",
    "    x_c = _dwt1d(x, lohi, -1)\n",
    "    y_c = _dwt1d(x_c.flatten(1, 2), lohi, -2)\n",
    "    z_c = _dwt1d(y_c.flatten(1, 2), lohi, -3)\n",
    "    return z_c.reshape(\n",
    "        z_c.shape[0], 8, x.shape[1], z_c.shape[3], z_c.shape[4], z_c.shape[5]\n",
    "    )\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _idwt3(x: torch.Tensor, lohi: torch.Tensor) -> torch.Tensor:\n",
    "    lll, hll, lhl, hhl, llh, hlh, lhh, hhh = x.unbind(1)\n",
    "\n",
    "    ll = _idwt1d(lll, llh, lohi, dim=-3)\n",
    "    hl = _idwt1d(hll, hlh, lohi, dim=-3)\n",
    "\n",
    "    lh = _idwt1d(lhl, lhh, lohi, dim=-3)\n",
    "    hh = _idwt1d(hhl, hhh, lohi, dim=-3)\n",
    "\n",
    "    l = _idwt1d(ll, lh, lohi, dim=-2)\n",
    "    h = _idwt1d(hl, hh, lohi, dim=-2)\n",
    "    y = _idwt1d(l, h, lohi, dim=-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywt import Wavelet\n",
    "\n",
    "def _to_wavelet_coefs(wavelet: str | torch.Tensor | Wavelet) -> torch.Tensor:\n",
    "    match wavelet:\n",
    "        case str():\n",
    "            return torch.tensor(Wavelet(wavelet).filter_bank)[2:]\n",
    "        case torch.Tensor():\n",
    "            return wavelet\n",
    "        case Wavelet():\n",
    "            return torch.tensor(wavelet.filter_bank)[2:]\n",
    "        case _:\n",
    "            raise Exception(\"\")\n",
    "\n",
    "def dwt2(x: torch.Tensor, wavelet: str | torch.Tensor | Wavelet) -> torch.Tensor:\n",
    "    \"\"\"performs the 2D discrete wavelet transform\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): [N,C,H,W] data\n",
    "        wavelet (str | torch.Tensor | Wavelet): wavelet\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: dwt coefs of shape [M,4,C,H_out,W_out] \\\\\n",
    "            (coef oder: cA,cV,cW,cD)\n",
    "    \"\"\"\n",
    "    filter = _to_wavelet_coefs(wavelet).to(x.device)\n",
    "    return _dwt2(x, filter)\n",
    "\n",
    "\n",
    "def idwt2(x: torch.Tensor, wavelet: str | torch.Tensor | Wavelet) -> torch.Tensor:\n",
    "    \"\"\"performs the 2D inverse discrete wavelet transform\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): [N,4,C,H,W] average and detail coefs\n",
    "        wavelet (str | torch.Tensor | Wavelet): wavelet\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: reconstructed tensor\n",
    "    \"\"\"\n",
    "    lohi = _to_wavelet_coefs(wavelet).to(x.device)\n",
    "    return _idwt2(x, lohi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 32, 32]), torch.Size([64, 3, 64, 64]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_up = InverseWaveDownsample(channels=3)\n",
    "inp = torch.randn((64, 3, 32, 32))\n",
    "op = model_up(inp)\n",
    "inp.shape, op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db stands for Daubechies \n",
    "# check https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html\n",
    "\n",
    "x = torch.rand(8,3,100,100)\n",
    "coefs = dwt2(x,\"db2\") # coefs of shape (1,2,3,50)\n",
    "# reconstruct signal from coefficients\n",
    "y = idwt2(coefs,\"db2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 100, 100]),\n",
       " torch.Size([8, 4, 3, 50, 50]),\n",
       " torch.Size([8, 3, 100, 100]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using haar wavelets\n",
    "x = torch.rand(8,3,100,100)\n",
    "coefs = dwt2(x,\"haar\") # coefs of shape (1,2,3,50)\n",
    "# reconstruct signal from coefficients\n",
    "y = idwt2(coefs,\"haar\")\n",
    "x.shape, coefs.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4, 3, 51, 51]),\n",
       " torch.Size([8, 3, 100, 100]),\n",
       " False,\n",
       " tensor(2.9802e-07))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.shape, y.shape, torch.allclose(x, y), (x-y).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 51, 51])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcoefs = coefs.flatten(1,2)\n",
    "fcoefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(fcoefs[:,:3], coefs[:,0]), torch.equal(fcoefs[:,3:6], coefs[:,1]), torch.equal(fcoefs[:,6:9], coefs[:,2]), torch.equal(fcoefs[:,9:], coefs[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "xf1 = DWTForward(J=1, mode='zero', wave='db1') \n",
    "\n",
    "class WaveDownsample(nn.Module) :\n",
    "    def __init__(self, mult = 2, channels=1, final_dim = 16, dropout = 0.5,) :\n",
    "        super().__init__()\n",
    "        self.feedforward = nn.Sequential(\n",
    "                nn.Conv2d(final_dim, final_dim*mult,1),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Conv2d(final_dim*mult, final_dim, 1),\n",
    "                nn.Conv2d(final_dim, channels, 3, 1, 1),\n",
    "                nn.BatchNorm2d(channels)\n",
    "            \n",
    "            )\n",
    "\n",
    "        self.reduction = nn.Conv2d(final_dim, int(final_dim/4), 1)\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(channels, int(final_dim/2), 3, 1, 1),\n",
    "            nn.Conv2d(int(final_dim/2), final_dim, 3, 1, 1)\n",
    "        )\n",
    "    def forward(self, x) :\n",
    "        x = self.pre(x)\n",
    "        b, c, h, w = x.shape\n",
    "        x = self.reduction(x) # c/4, h, w\n",
    "        Y1, Yh = xf1.to(x.device)(x)\n",
    "        x = torch.reshape(Yh[0], (b, int(c*3/4), int(h/2), int(w/2)))\n",
    "        x = torch.cat((Y1,x), dim = 1) # c, h/2, w/2\n",
    "        return self.feedforward(x)\n",
    "    \n",
    "class InverseWaveDownsample(nn.Module) :\n",
    "    def __init__(self, mult = 2, channels=1, final_dim = 16, dropout = 0.5,) :\n",
    "        super().__init__()\n",
    "        self.feedforward = nn.Sequential(\n",
    "                nn.Conv2d(channels, final_dim, 3, 1, 1),\n",
    "                nn.Conv2d(final_dim, final_dim*mult, 1),\n",
    "                nn.BatchNorm2d(final_dim*mult),\n",
    "                nn.Conv2d(final_dim*mult, final_dim,1),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout),\n",
    "            \n",
    "            )\n",
    "\n",
    "        self.reduction = nn.Conv2d(final_dim, final_dim*4, 1)\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(final_dim, int(final_dim/2), 3, 1, 1),\n",
    "            nn.Conv2d(int(final_dim/2), channels, 3, 1, 1)\n",
    "        )\n",
    "    def forward(self, x) :\n",
    "        x = self.feedforward(x)\n",
    "        b, c, h, w = x.shape\n",
    "        x = self.reduction(x) # 4*c, h, w\n",
    "        temp = x.chunk(4, dim=1)\n",
    "        coefs = torch.stack(temp).transpose(0,1)\n",
    "        x = idwt2(coefs,\"db1\") # c,2*h,2*w\n",
    "        return self.pre(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 3, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,12,32,32)).chunk(4, dim=1)\n",
    "torch.stack(a).transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 12, 32, 32]), torch.Size([64, 3, 64, 64]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn((64,12,32,32))\n",
    "temp = inp.chunk(4, dim=1)\n",
    "coefs = torch.stack(temp).transpose(0,1)\n",
    "y = idwt2(coefs,\"haar\")\n",
    "inp.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 32, 32]), torch.Size([64, 3, 16, 16]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_down = WaveDownsample(channels=3)\n",
    "inp = torch.randn((64, 3, 32, 32))\n",
    "op = model_down(inp)\n",
    "inp.shape, op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 32, 32]), torch.Size([64, 3, 64, 64]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_up = InverseWaveDownsample(channels=3)\n",
    "inp = torch.randn((64, 3, 32, 32))\n",
    "op = model_up(inp)\n",
    "inp.shape, op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 32, 32]), torch.Size([64, 12, 16, 16]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn((64,3,32,32))\n",
    "b, c, h, w = inp.shape\n",
    "Y1, Yh = xf1(inp)\n",
    "mid = torch.reshape(Yh[0], (b, int(c*3), int(h/2), int(w/2)))\n",
    "x=mid = torch.cat((Y1,mid), dim = 1) # c, h/2, w/2\n",
    "inp.shape, mid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 12, 16, 16]), torch.Size([64, 3, 32, 32]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = mid.chunk(4, dim=1)\n",
    "coefs = torch.stack(temp).transpose(0,1)\n",
    "y = idwt2(coefs,\"db1\")\n",
    "mid.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, tensor(5.9326))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(inp, y), (inp-y).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 12, 16, 16]), torch.Size([64, 12, 16, 16]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid2 = dwt2(inp, 'db1').flatten(1,2)\n",
    "mid.shape, mid2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8996)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mid-mid2).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "model = WaveUNetModel(\n",
    "    in_channels=3,\n",
    "    model_channels=96,\n",
    "    out_channels=3,\n",
    "    use_idwt=True,\n",
    "    channel_mult=(1, 2, 2),\n",
    "    attention_resolutions=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4321'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9876'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "a = deque([6, 7, 8, 9])\n",
    "''.join(map(str, reversed(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"zh-plus/tiny-imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(ds['train'], batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TinyImageNet(Dataset) :\n",
    "    def __init__(self, data, split='train', transforms=None) :\n",
    "        assert split in ['train', 'test'], f'Split {split} not supported'\n",
    "        self.data = data[split]\n",
    "        self.transforms = transforms\n",
    "    def __len__(self) :\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx) :\n",
    "        ret = self.transforms(np.array(self.data[idx]['image']))\n",
    "        label = self.data[idx]['label']\n",
    "        if ret.shape[-3]==1 :\n",
    "            ret = torch.repeat_interleave(ret, repeats=3, dim=-3)\n",
    "        return ret, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.randn((1,64,64))\n",
    "torch.repeat_interleave(temp, repeats=3, dim=-3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"zh-plus/tiny-imagenet\")\n",
    "dataset = TinyImageNet(ds, transforms=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 64, 64]), torch.Size([64]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 26, 145,  34,  88,  81,  20,  61,   1, 177,  79,  20,  54,  90,  67,\n",
       "         37, 183, 161, 114,  31, 185, 158,  18, 123,  45,  60, 135,  47,  31,\n",
       "         53,  69,  20, 102,   9, 195, 164,  57, 135, 146, 187, 128, 167,  42,\n",
       "          8,  84, 108, 109, 135,  64, 195,  17, 122, 176, 132,  26, 183,  39,\n",
       "          2, 145, 183,  67, 188, 143,  50,  51])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13800003"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "model = UNetModel(\n",
    "     in_channels=3,\n",
    "    model_channels=96,\n",
    "    out_channels=3,\n",
    "    channel_mult=(1, 2, 2),\n",
    "    attention_resolutions=[]\n",
    "\n",
    ")\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device='cpu'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:29<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.029611587524414\n"
     ]
    }
   ],
   "source": [
    "nparams, fid, losslog, imgs, model = run(model, name='test', dataset_name='tinyImageNet', epochs=5, batchsize=64, timesteps=500, device='cpu', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([64, 3, 64, 64])\n",
      "1 torch.Size([64, 3, 64, 64])\n",
      "2 torch.Size([64, 3, 64, 64])\n",
      "3 torch.Size([64, 3, 64, 64])\n",
      "4 torch.Size([64, 3, 64, 64])\n",
      "5 torch.Size([64, 3, 64, 64])\n",
      "6 torch.Size([64, 3, 64, 64])\n",
      "7 torch.Size([64, 3, 64, 64])\n",
      "8 torch.Size([64, 3, 64, 64])\n",
      "9 torch.Size([64, 3, 64, 64])\n",
      "10 torch.Size([64, 3, 64, 64])\n",
      "11 torch.Size([64, 3, 64, 64])\n",
      "12 torch.Size([64, 3, 64, 64])\n",
      "13 torch.Size([64, 3, 64, 64])\n",
      "14 torch.Size([64, 3, 64, 64])\n",
      "15 torch.Size([64, 3, 64, 64])\n",
      "16 torch.Size([64, 3, 64, 64])\n",
      "17 torch.Size([64, 3, 64, 64])\n",
      "18 torch.Size([64, 3, 64, 64])\n",
      "19 torch.Size([64, 3, 64, 64])\n",
      "20 torch.Size([64, 3, 64, 64])\n",
      "21 torch.Size([64, 3, 64, 64])\n",
      "22 torch.Size([64, 3, 64, 64])\n",
      "23 torch.Size([64, 3, 64, 64])\n",
      "24 torch.Size([64, 3, 64, 64])\n",
      "25 torch.Size([64, 3, 64, 64])\n",
      "26 torch.Size([64, 3, 64, 64])\n",
      "27 torch.Size([64, 3, 64, 64])\n",
      "28 torch.Size([64, 3, 64, 64])\n",
      "29 torch.Size([64, 3, 64, 64])\n",
      "30 torch.Size([64, 3, 64, 64])\n",
      "31 torch.Size([64, 3, 64, 64])\n",
      "32 torch.Size([64, 3, 64, 64])\n",
      "33 torch.Size([64, 3, 64, 64])\n",
      "34 torch.Size([64, 3, 64, 64])\n",
      "35 torch.Size([64, 3, 64, 64])\n",
      "36 torch.Size([64, 3, 64, 64])\n",
      "37 torch.Size([64, 3, 64, 64])\n",
      "38 torch.Size([64, 3, 64, 64])\n",
      "39 torch.Size([64, 3, 64, 64])\n",
      "40 torch.Size([64, 3, 64, 64])\n",
      "41 torch.Size([64, 3, 64, 64])\n",
      "42 torch.Size([64, 3, 64, 64])\n",
      "43 torch.Size([64, 3, 64, 64])\n",
      "44 torch.Size([64, 3, 64, 64])\n",
      "45 torch.Size([64, 3, 64, 64])\n",
      "46 torch.Size([64, 3, 64, 64])\n",
      "47 torch.Size([64, 3, 64, 64])\n",
      "48 torch.Size([64, 3, 64, 64])\n",
      "49 torch.Size([64, 3, 64, 64])\n",
      "50 torch.Size([64, 3, 64, 64])\n",
      "51 torch.Size([64, 3, 64, 64])\n",
      "52 torch.Size([64, 3, 64, 64])\n",
      "53 torch.Size([64, 3, 64, 64])\n",
      "54 torch.Size([64, 3, 64, 64])\n",
      "55 torch.Size([64, 3, 64, 64])\n",
      "56 torch.Size([64, 3, 64, 64])\n",
      "57 torch.Size([64, 3, 64, 64])\n",
      "58 torch.Size([64, 3, 64, 64])\n",
      "59 torch.Size([64, 3, 64, 64])\n",
      "60 torch.Size([64, 3, 64, 64])\n",
      "61 torch.Size([64, 3, 64, 64])\n",
      "62 torch.Size([64, 3, 64, 64])\n",
      "63 torch.Size([64, 3, 64, 64])\n",
      "64 torch.Size([64, 3, 64, 64])\n",
      "65 torch.Size([64, 3, 64, 64])\n",
      "66 torch.Size([64, 3, 64, 64])\n",
      "67 torch.Size([64, 3, 64, 64])\n",
      "68 torch.Size([64, 3, 64, 64])\n",
      "69 torch.Size([64, 3, 64, 64])\n",
      "70 torch.Size([64, 3, 64, 64])\n",
      "71 torch.Size([64, 3, 64, 64])\n",
      "72 torch.Size([64, 3, 64, 64])\n",
      "73 torch.Size([64, 3, 64, 64])\n",
      "74 torch.Size([64, 3, 64, 64])\n",
      "75 torch.Size([64, 3, 64, 64])\n",
      "76 torch.Size([64, 3, 64, 64])\n",
      "77 torch.Size([64, 3, 64, 64])\n",
      "78 torch.Size([64, 3, 64, 64])\n",
      "79 torch.Size([64, 3, 64, 64])\n",
      "80 torch.Size([64, 3, 64, 64])\n",
      "81 torch.Size([64, 3, 64, 64])\n",
      "82 torch.Size([64, 3, 64, 64])\n",
      "83 torch.Size([64, 3, 64, 64])\n",
      "84 torch.Size([64, 3, 64, 64])\n",
      "85 torch.Size([64, 3, 64, 64])\n",
      "86 torch.Size([64, 3, 64, 64])\n",
      "87 torch.Size([64, 3, 64, 64])\n",
      "88 torch.Size([64, 3, 64, 64])\n",
      "89 torch.Size([64, 3, 64, 64])\n",
      "90 torch.Size([64, 3, 64, 64])\n",
      "91 torch.Size([64, 3, 64, 64])\n",
      "92 torch.Size([64, 3, 64, 64])\n",
      "93 torch.Size([64, 3, 64, 64])\n",
      "94 torch.Size([64, 3, 64, 64])\n",
      "95 torch.Size([64, 3, 64, 64])\n",
      "96 torch.Size([64, 3, 64, 64])\n",
      "97 torch.Size([64, 3, 64, 64])\n",
      "98 torch.Size([64, 3, 64, 64])\n",
      "99 torch.Size([64, 3, 64, 64])\n",
      "100 torch.Size([64, 3, 64, 64])\n",
      "101 torch.Size([64, 3, 64, 64])\n",
      "102 torch.Size([64, 3, 64, 64])\n",
      "103 torch.Size([64, 3, 64, 64])\n",
      "104 torch.Size([64, 3, 64, 64])\n",
      "105 torch.Size([64, 3, 64, 64])\n",
      "106 torch.Size([64, 3, 64, 64])\n",
      "107 torch.Size([64, 3, 64, 64])\n",
      "108 torch.Size([64, 3, 64, 64])\n",
      "109 torch.Size([64, 3, 64, 64])\n",
      "110 torch.Size([64, 3, 64, 64])\n",
      "111 torch.Size([64, 3, 64, 64])\n",
      "112 torch.Size([64, 3, 64, 64])\n",
      "113 torch.Size([64, 3, 64, 64])\n",
      "114 torch.Size([64, 3, 64, 64])\n",
      "115 torch.Size([64, 3, 64, 64])\n",
      "116 torch.Size([64, 3, 64, 64])\n",
      "117 torch.Size([64, 3, 64, 64])\n",
      "118 torch.Size([64, 3, 64, 64])\n",
      "119 torch.Size([64, 3, 64, 64])\n",
      "120 torch.Size([64, 3, 64, 64])\n",
      "121 torch.Size([64, 3, 64, 64])\n",
      "122 torch.Size([64, 3, 64, 64])\n",
      "123 torch.Size([64, 3, 64, 64])\n",
      "124 torch.Size([64, 3, 64, 64])\n",
      "125 torch.Size([64, 3, 64, 64])\n",
      "126 torch.Size([64, 3, 64, 64])\n",
      "127 torch.Size([64, 3, 64, 64])\n",
      "128 torch.Size([64, 3, 64, 64])\n",
      "129 torch.Size([64, 3, 64, 64])\n",
      "130 torch.Size([64, 3, 64, 64])\n",
      "131 torch.Size([64, 3, 64, 64])\n",
      "132 torch.Size([64, 3, 64, 64])\n",
      "133 torch.Size([64, 3, 64, 64])\n",
      "134 torch.Size([64, 3, 64, 64])\n",
      "135 torch.Size([64, 3, 64, 64])\n",
      "136 torch.Size([64, 3, 64, 64])\n",
      "137 torch.Size([64, 3, 64, 64])\n",
      "138 torch.Size([64, 3, 64, 64])\n",
      "139 torch.Size([64, 3, 64, 64])\n",
      "140 torch.Size([64, 3, 64, 64])\n",
      "141 torch.Size([64, 3, 64, 64])\n",
      "142 torch.Size([64, 3, 64, 64])\n",
      "143 torch.Size([64, 3, 64, 64])\n",
      "144 torch.Size([64, 3, 64, 64])\n",
      "145 torch.Size([64, 3, 64, 64])\n",
      "146 torch.Size([64, 3, 64, 64])\n",
      "147 torch.Size([64, 3, 64, 64])\n",
      "148 torch.Size([64, 3, 64, 64])\n",
      "149 torch.Size([64, 3, 64, 64])\n",
      "150 torch.Size([64, 3, 64, 64])\n",
      "151 torch.Size([64, 3, 64, 64])\n",
      "152 torch.Size([64, 3, 64, 64])\n",
      "153 torch.Size([64, 3, 64, 64])\n",
      "154 torch.Size([64, 3, 64, 64])\n",
      "155 torch.Size([64, 3, 64, 64])\n",
      "156 torch.Size([64, 3, 64, 64])\n",
      "157 torch.Size([64, 3, 64, 64])\n",
      "158 torch.Size([64, 3, 64, 64])\n",
      "159 torch.Size([64, 3, 64, 64])\n",
      "160 torch.Size([64, 3, 64, 64])\n",
      "161 torch.Size([64, 3, 64, 64])\n",
      "162 torch.Size([64, 3, 64, 64])\n",
      "163 torch.Size([64, 3, 64, 64])\n",
      "164 torch.Size([64, 3, 64, 64])\n",
      "165 torch.Size([64, 3, 64, 64])\n",
      "166 torch.Size([64, 3, 64, 64])\n",
      "167 torch.Size([64, 3, 64, 64])\n",
      "168 torch.Size([64, 3, 64, 64])\n",
      "169 torch.Size([64, 3, 64, 64])\n",
      "170 torch.Size([64, 3, 64, 64])\n",
      "171 torch.Size([64, 3, 64, 64])\n",
      "172 torch.Size([64, 3, 64, 64])\n",
      "173 torch.Size([64, 3, 64, 64])\n",
      "174 torch.Size([64, 3, 64, 64])\n",
      "175 torch.Size([64, 3, 64, 64])\n",
      "176 torch.Size([64, 3, 64, 64])\n",
      "177 torch.Size([64, 3, 64, 64])\n",
      "178 torch.Size([64, 3, 64, 64])\n",
      "179 torch.Size([64, 3, 64, 64])\n",
      "180 torch.Size([64, 3, 64, 64])\n",
      "181 torch.Size([64, 3, 64, 64])\n",
      "182 torch.Size([64, 3, 64, 64])\n",
      "183 torch.Size([64, 3, 64, 64])\n",
      "184 torch.Size([64, 3, 64, 64])\n",
      "185 torch.Size([64, 3, 64, 64])\n",
      "186 torch.Size([64, 3, 64, 64])\n",
      "187 torch.Size([64, 3, 64, 64])\n",
      "188 torch.Size([64, 3, 64, 64])\n",
      "189 torch.Size([64, 3, 64, 64])\n",
      "190 torch.Size([64, 3, 64, 64])\n",
      "191 torch.Size([64, 3, 64, 64])\n",
      "192 torch.Size([64, 3, 64, 64])\n",
      "193 torch.Size([64, 3, 64, 64])\n",
      "194 torch.Size([64, 3, 64, 64])\n",
      "195 torch.Size([64, 3, 64, 64])\n",
      "196 torch.Size([64, 3, 64, 64])\n",
      "197 torch.Size([64, 3, 64, 64])\n",
      "198 torch.Size([64, 3, 64, 64])\n",
      "199 torch.Size([64, 3, 64, 64])\n",
      "200 torch.Size([64, 3, 64, 64])\n",
      "201 torch.Size([64, 3, 64, 64])\n",
      "202 torch.Size([64, 3, 64, 64])\n",
      "203 torch.Size([64, 3, 64, 64])\n",
      "204 torch.Size([64, 3, 64, 64])\n",
      "205 torch.Size([64, 3, 64, 64])\n",
      "206 torch.Size([64, 3, 64, 64])\n",
      "207 torch.Size([64, 3, 64, 64])\n",
      "208 torch.Size([64, 3, 64, 64])\n",
      "209 torch.Size([64, 3, 64, 64])\n",
      "210 torch.Size([64, 3, 64, 64])\n",
      "211 torch.Size([64, 3, 64, 64])\n",
      "212 torch.Size([64, 3, 64, 64])\n",
      "213 torch.Size([64, 3, 64, 64])\n",
      "214 torch.Size([64, 3, 64, 64])\n",
      "215 torch.Size([64, 3, 64, 64])\n",
      "216 torch.Size([64, 3, 64, 64])\n",
      "217 torch.Size([64, 3, 64, 64])\n",
      "218 torch.Size([64, 3, 64, 64])\n",
      "219 torch.Size([64, 3, 64, 64])\n",
      "220 torch.Size([64, 3, 64, 64])\n",
      "221 torch.Size([64, 3, 64, 64])\n",
      "222 torch.Size([64, 3, 64, 64])\n",
      "223 torch.Size([64, 3, 64, 64])\n",
      "224 torch.Size([64, 3, 64, 64])\n",
      "225 torch.Size([64, 3, 64, 64])\n",
      "226 torch.Size([64, 3, 64, 64])\n",
      "227 torch.Size([64, 3, 64, 64])\n",
      "228 torch.Size([64, 3, 64, 64])\n",
      "229 torch.Size([64, 3, 64, 64])\n",
      "230 torch.Size([64, 3, 64, 64])\n",
      "231 torch.Size([64, 3, 64, 64])\n",
      "232 torch.Size([64, 3, 64, 64])\n",
      "233 torch.Size([64, 3, 64, 64])\n",
      "234 torch.Size([64, 3, 64, 64])\n",
      "235 torch.Size([64, 3, 64, 64])\n",
      "236 torch.Size([64, 3, 64, 64])\n",
      "237 torch.Size([64, 3, 64, 64])\n",
      "238 torch.Size([64, 3, 64, 64])\n",
      "239 torch.Size([64, 3, 64, 64])\n",
      "240 torch.Size([64, 3, 64, 64])\n",
      "241 torch.Size([64, 3, 64, 64])\n",
      "242 torch.Size([64, 3, 64, 64])\n",
      "243 torch.Size([64, 3, 64, 64])\n",
      "244 torch.Size([64, 3, 64, 64])\n",
      "245 torch.Size([64, 3, 64, 64])\n",
      "246 torch.Size([64, 3, 64, 64])\n",
      "247 torch.Size([64, 3, 64, 64])\n",
      "248 torch.Size([64, 3, 64, 64])\n",
      "249 torch.Size([64, 3, 64, 64])\n",
      "250 torch.Size([64, 3, 64, 64])\n",
      "251 torch.Size([64, 3, 64, 64])\n",
      "252 torch.Size([64, 3, 64, 64])\n",
      "253 torch.Size([64, 3, 64, 64])\n",
      "254 torch.Size([64, 3, 64, 64])\n",
      "255 torch.Size([64, 3, 64, 64])\n",
      "256 torch.Size([64, 3, 64, 64])\n",
      "257 torch.Size([64, 3, 64, 64])\n",
      "258 torch.Size([64, 3, 64, 64])\n",
      "259 torch.Size([64, 3, 64, 64])\n",
      "260 torch.Size([64, 3, 64, 64])\n",
      "261 torch.Size([64, 3, 64, 64])\n",
      "262 torch.Size([64, 3, 64, 64])\n",
      "263 torch.Size([64, 3, 64, 64])\n",
      "264 torch.Size([64, 3, 64, 64])\n",
      "265 torch.Size([64, 3, 64, 64])\n",
      "266 torch.Size([64, 3, 64, 64])\n",
      "267 torch.Size([64, 3, 64, 64])\n",
      "268 torch.Size([64, 3, 64, 64])\n",
      "269 torch.Size([64, 3, 64, 64])\n",
      "270 torch.Size([64, 3, 64, 64])\n",
      "271 torch.Size([64, 3, 64, 64])\n",
      "272 torch.Size([64, 3, 64, 64])\n",
      "273 torch.Size([64, 3, 64, 64])\n",
      "274 torch.Size([64, 3, 64, 64])\n",
      "275 torch.Size([64, 3, 64, 64])\n",
      "276 torch.Size([64, 3, 64, 64])\n",
      "277 torch.Size([64, 3, 64, 64])\n",
      "278 torch.Size([64, 3, 64, 64])\n",
      "279 torch.Size([64, 3, 64, 64])\n",
      "280 torch.Size([64, 3, 64, 64])\n",
      "281 torch.Size([64, 3, 64, 64])\n",
      "282 torch.Size([64, 3, 64, 64])\n",
      "283 torch.Size([64, 3, 64, 64])\n",
      "284 torch.Size([64, 3, 64, 64])\n",
      "285 torch.Size([64, 3, 64, 64])\n",
      "286 torch.Size([64, 3, 64, 64])\n",
      "287 torch.Size([64, 3, 64, 64])\n",
      "288 torch.Size([64, 3, 64, 64])\n",
      "289 torch.Size([64, 3, 64, 64])\n",
      "290 torch.Size([64, 3, 64, 64])\n",
      "291 torch.Size([64, 3, 64, 64])\n",
      "292 torch.Size([64, 3, 64, 64])\n",
      "293 torch.Size([64, 3, 64, 64])\n",
      "294 torch.Size([64, 3, 64, 64])\n",
      "295 torch.Size([64, 3, 64, 64])\n",
      "296 torch.Size([64, 3, 64, 64])\n",
      "297 torch.Size([64, 3, 64, 64])\n",
      "298 torch.Size([64, 3, 64, 64])\n",
      "299 torch.Size([64, 3, 64, 64])\n",
      "300 torch.Size([64, 3, 64, 64])\n",
      "301 torch.Size([64, 3, 64, 64])\n",
      "302 torch.Size([64, 3, 64, 64])\n",
      "303 torch.Size([64, 3, 64, 64])\n",
      "304 torch.Size([64, 3, 64, 64])\n",
      "305 torch.Size([64, 3, 64, 64])\n",
      "306 torch.Size([64, 3, 64, 64])\n",
      "307 torch.Size([64, 3, 64, 64])\n",
      "308 torch.Size([64, 3, 64, 64])\n",
      "309 torch.Size([64, 3, 64, 64])\n",
      "310 torch.Size([64, 3, 64, 64])\n",
      "311 torch.Size([64, 3, 64, 64])\n",
      "312 torch.Size([64, 3, 64, 64])\n",
      "313 torch.Size([64, 3, 64, 64])\n",
      "314 torch.Size([64, 3, 64, 64])\n",
      "315 torch.Size([64, 3, 64, 64])\n",
      "316 torch.Size([64, 3, 64, 64])\n",
      "317 torch.Size([64, 3, 64, 64])\n",
      "318 torch.Size([64, 3, 64, 64])\n",
      "319 torch.Size([64, 3, 64, 64])\n",
      "320 torch.Size([64, 3, 64, 64])\n",
      "321 torch.Size([64, 3, 64, 64])\n",
      "322 torch.Size([64, 3, 64, 64])\n",
      "323 torch.Size([64, 3, 64, 64])\n",
      "324 torch.Size([64, 3, 64, 64])\n",
      "325 torch.Size([64, 3, 64, 64])\n",
      "326 torch.Size([64, 3, 64, 64])\n",
      "327 torch.Size([64, 3, 64, 64])\n",
      "328 torch.Size([64, 3, 64, 64])\n",
      "329 torch.Size([64, 3, 64, 64])\n",
      "330 torch.Size([64, 3, 64, 64])\n",
      "331 torch.Size([64, 3, 64, 64])\n",
      "332 torch.Size([64, 3, 64, 64])\n",
      "333 torch.Size([64, 3, 64, 64])\n",
      "334 torch.Size([64, 3, 64, 64])\n",
      "335 torch.Size([64, 3, 64, 64])\n",
      "336 torch.Size([64, 3, 64, 64])\n",
      "337 torch.Size([64, 3, 64, 64])\n",
      "338 torch.Size([64, 3, 64, 64])\n",
      "339 torch.Size([64, 3, 64, 64])\n",
      "340 torch.Size([64, 3, 64, 64])\n",
      "341 torch.Size([64, 3, 64, 64])\n",
      "342 torch.Size([64, 3, 64, 64])\n",
      "343 torch.Size([64, 3, 64, 64])\n",
      "344 torch.Size([64, 3, 64, 64])\n",
      "345 torch.Size([64, 3, 64, 64])\n",
      "346 torch.Size([64, 3, 64, 64])\n",
      "347 torch.Size([64, 3, 64, 64])\n",
      "348 torch.Size([64, 3, 64, 64])\n",
      "349 torch.Size([64, 3, 64, 64])\n",
      "350 torch.Size([64, 3, 64, 64])\n",
      "351 torch.Size([64, 3, 64, 64])\n",
      "352 torch.Size([64, 3, 64, 64])\n",
      "353 torch.Size([64, 3, 64, 64])\n",
      "354 torch.Size([64, 3, 64, 64])\n",
      "355 torch.Size([64, 3, 64, 64])\n",
      "356 torch.Size([64, 3, 64, 64])\n",
      "357 torch.Size([64, 3, 64, 64])\n",
      "358 torch.Size([64, 3, 64, 64])\n",
      "359 torch.Size([64, 3, 64, 64])\n",
      "360 torch.Size([64, 3, 64, 64])\n",
      "361 torch.Size([64, 3, 64, 64])\n",
      "362 torch.Size([64, 3, 64, 64])\n",
      "363 torch.Size([64, 3, 64, 64])\n",
      "364 torch.Size([64, 3, 64, 64])\n",
      "365 torch.Size([64, 3, 64, 64])\n",
      "366 torch.Size([64, 3, 64, 64])\n",
      "367 torch.Size([64, 3, 64, 64])\n",
      "368 torch.Size([64, 3, 64, 64])\n",
      "369 torch.Size([64, 3, 64, 64])\n",
      "370 torch.Size([64, 3, 64, 64])\n",
      "371 torch.Size([64, 3, 64, 64])\n",
      "372 torch.Size([64, 3, 64, 64])\n",
      "373 torch.Size([64, 3, 64, 64])\n",
      "374 torch.Size([64, 3, 64, 64])\n",
      "375 torch.Size([64, 3, 64, 64])\n",
      "376 torch.Size([64, 3, 64, 64])\n",
      "377 torch.Size([64, 3, 64, 64])\n",
      "378 torch.Size([64, 3, 64, 64])\n",
      "379 torch.Size([64, 3, 64, 64])\n",
      "380 torch.Size([64, 3, 64, 64])\n",
      "381 torch.Size([64, 3, 64, 64])\n",
      "382 torch.Size([64, 3, 64, 64])\n",
      "383 torch.Size([64, 3, 64, 64])\n",
      "384 torch.Size([64, 3, 64, 64])\n",
      "385 torch.Size([64, 3, 64, 64])\n",
      "386 torch.Size([64, 3, 64, 64])\n",
      "387 torch.Size([64, 3, 64, 64])\n",
      "388 torch.Size([64, 3, 64, 64])\n",
      "389 torch.Size([64, 3, 64, 64])\n",
      "390 torch.Size([64, 3, 64, 64])\n",
      "391 torch.Size([64, 3, 64, 64])\n",
      "392 torch.Size([64, 3, 64, 64])\n",
      "393 torch.Size([64, 3, 64, 64])\n",
      "394 torch.Size([64, 3, 64, 64])\n",
      "395 torch.Size([64, 3, 64, 64])\n",
      "396 torch.Size([64, 3, 64, 64])\n",
      "397 torch.Size([64, 3, 64, 64])\n",
      "398 torch.Size([64, 3, 64, 64])\n",
      "399 torch.Size([64, 3, 64, 64])\n",
      "400 torch.Size([64, 3, 64, 64])\n",
      "401 torch.Size([64, 3, 64, 64])\n",
      "402 torch.Size([64, 3, 64, 64])\n",
      "403 torch.Size([64, 3, 64, 64])\n",
      "404 torch.Size([64, 3, 64, 64])\n",
      "405 torch.Size([64, 3, 64, 64])\n",
      "406 torch.Size([64, 3, 64, 64])\n",
      "407 torch.Size([64, 3, 64, 64])\n",
      "408 torch.Size([64, 3, 64, 64])\n",
      "409 torch.Size([64, 3, 64, 64])\n",
      "410 torch.Size([64, 3, 64, 64])\n",
      "411 torch.Size([64, 3, 64, 64])\n",
      "412 torch.Size([64, 3, 64, 64])\n",
      "413 torch.Size([64, 3, 64, 64])\n",
      "414 torch.Size([64, 3, 64, 64])\n",
      "415 torch.Size([64, 3, 64, 64])\n",
      "416 torch.Size([64, 3, 64, 64])\n",
      "417 torch.Size([64, 3, 64, 64])\n",
      "418 torch.Size([64, 3, 64, 64])\n",
      "419 torch.Size([64, 3, 64, 64])\n",
      "420 torch.Size([64, 3, 64, 64])\n",
      "421 torch.Size([64, 3, 64, 64])\n",
      "422 torch.Size([64, 3, 64, 64])\n",
      "423 torch.Size([64, 3, 64, 64])\n",
      "424 torch.Size([64, 3, 64, 64])\n",
      "425 torch.Size([64, 3, 64, 64])\n",
      "426 torch.Size([64, 3, 64, 64])\n",
      "427 torch.Size([64, 3, 64, 64])\n",
      "428 torch.Size([64, 3, 64, 64])\n",
      "429 torch.Size([64, 3, 64, 64])\n",
      "430 torch.Size([64, 3, 64, 64])\n",
      "431 torch.Size([64, 3, 64, 64])\n",
      "432 torch.Size([64, 3, 64, 64])\n",
      "433 torch.Size([64, 3, 64, 64])\n",
      "434 torch.Size([64, 3, 64, 64])\n",
      "435 torch.Size([64, 3, 64, 64])\n",
      "436 torch.Size([64, 3, 64, 64])\n",
      "437 torch.Size([64, 3, 64, 64])\n",
      "438 torch.Size([64, 3, 64, 64])\n",
      "439 torch.Size([64, 3, 64, 64])\n",
      "440 torch.Size([64, 3, 64, 64])\n",
      "441 torch.Size([64, 3, 64, 64])\n",
      "442 torch.Size([64, 3, 64, 64])\n",
      "443 torch.Size([64, 3, 64, 64])\n",
      "444 torch.Size([64, 3, 64, 64])\n",
      "445 torch.Size([64, 3, 64, 64])\n",
      "446 torch.Size([64, 3, 64, 64])\n",
      "447 torch.Size([64, 3, 64, 64])\n",
      "448 torch.Size([64, 3, 64, 64])\n",
      "449 torch.Size([64, 3, 64, 64])\n",
      "450 torch.Size([64, 3, 64, 64])\n",
      "451 torch.Size([64, 3, 64, 64])\n",
      "452 torch.Size([64, 3, 64, 64])\n",
      "453 torch.Size([64, 3, 64, 64])\n",
      "454 torch.Size([64, 3, 64, 64])\n",
      "455 torch.Size([64, 3, 64, 64])\n",
      "456 torch.Size([64, 3, 64, 64])\n",
      "457 torch.Size([64, 3, 64, 64])\n",
      "458 torch.Size([64, 3, 64, 64])\n",
      "459 torch.Size([64, 3, 64, 64])\n",
      "460 torch.Size([64, 3, 64, 64])\n",
      "461 torch.Size([64, 3, 64, 64])\n",
      "462 torch.Size([64, 3, 64, 64])\n",
      "463 torch.Size([64, 3, 64, 64])\n",
      "464 torch.Size([64, 3, 64, 64])\n",
      "465 torch.Size([64, 3, 64, 64])\n",
      "466 torch.Size([64, 3, 64, 64])\n",
      "467 torch.Size([64, 3, 64, 64])\n",
      "468 torch.Size([64, 3, 64, 64])\n",
      "469 torch.Size([64, 3, 64, 64])\n",
      "470 torch.Size([64, 3, 64, 64])\n",
      "471 torch.Size([64, 3, 64, 64])\n",
      "472 torch.Size([64, 3, 64, 64])\n",
      "473 torch.Size([64, 3, 64, 64])\n",
      "474 torch.Size([64, 3, 64, 64])\n",
      "475 torch.Size([64, 3, 64, 64])\n",
      "476 torch.Size([64, 3, 64, 64])\n",
      "477 torch.Size([64, 3, 64, 64])\n",
      "478 torch.Size([64, 3, 64, 64])\n",
      "479 torch.Size([64, 3, 64, 64])\n",
      "480 torch.Size([64, 3, 64, 64])\n",
      "481 torch.Size([64, 3, 64, 64])\n",
      "482 torch.Size([64, 3, 64, 64])\n",
      "483 torch.Size([64, 3, 64, 64])\n",
      "484 torch.Size([64, 3, 64, 64])\n",
      "485 torch.Size([64, 3, 64, 64])\n",
      "486 torch.Size([64, 3, 64, 64])\n",
      "487 torch.Size([64, 3, 64, 64])\n",
      "488 torch.Size([64, 3, 64, 64])\n",
      "489 torch.Size([64, 3, 64, 64])\n",
      "490 torch.Size([64, 3, 64, 64])\n",
      "491 torch.Size([64, 3, 64, 64])\n",
      "492 torch.Size([64, 3, 64, 64])\n",
      "493 torch.Size([64, 3, 64, 64])\n",
      "494 torch.Size([64, 3, 64, 64])\n",
      "495 torch.Size([64, 3, 64, 64])\n",
      "496 torch.Size([64, 3, 64, 64])\n",
      "497 torch.Size([64, 3, 64, 64])\n",
      "498 torch.Size([64, 3, 64, 64])\n",
      "499 torch.Size([64, 3, 64, 64])\n",
      "500 torch.Size([64, 3, 64, 64])\n",
      "501 torch.Size([64, 3, 64, 64])\n",
      "502 torch.Size([64, 3, 64, 64])\n",
      "503 torch.Size([64, 3, 64, 64])\n",
      "504 torch.Size([64, 3, 64, 64])\n",
      "505 torch.Size([64, 3, 64, 64])\n",
      "506 torch.Size([64, 3, 64, 64])\n",
      "507 torch.Size([64, 3, 64, 64])\n",
      "508 torch.Size([64, 3, 64, 64])\n",
      "509 torch.Size([64, 3, 64, 64])\n",
      "510 torch.Size([64, 3, 64, 64])\n",
      "511 torch.Size([64, 3, 64, 64])\n",
      "512 torch.Size([64, 3, 64, 64])\n",
      "513 torch.Size([64, 3, 64, 64])\n",
      "514 torch.Size([64, 3, 64, 64])\n",
      "515 torch.Size([64, 3, 64, 64])\n",
      "516 torch.Size([64, 3, 64, 64])\n",
      "517 torch.Size([64, 3, 64, 64])\n",
      "518 torch.Size([64, 3, 64, 64])\n",
      "519 torch.Size([64, 3, 64, 64])\n",
      "520 torch.Size([64, 3, 64, 64])\n",
      "521 torch.Size([64, 3, 64, 64])\n",
      "522 torch.Size([64, 3, 64, 64])\n",
      "523 torch.Size([64, 3, 64, 64])\n",
      "524 torch.Size([64, 3, 64, 64])\n",
      "525 torch.Size([64, 3, 64, 64])\n",
      "526 torch.Size([64, 3, 64, 64])\n",
      "527 torch.Size([64, 3, 64, 64])\n",
      "528 torch.Size([64, 3, 64, 64])\n",
      "529 torch.Size([64, 3, 64, 64])\n",
      "530 torch.Size([64, 3, 64, 64])\n",
      "531 torch.Size([64, 3, 64, 64])\n",
      "532 torch.Size([64, 3, 64, 64])\n",
      "533 torch.Size([64, 3, 64, 64])\n",
      "534 torch.Size([64, 3, 64, 64])\n",
      "535 torch.Size([64, 3, 64, 64])\n",
      "536 torch.Size([64, 3, 64, 64])\n",
      "537 torch.Size([64, 3, 64, 64])\n",
      "538 torch.Size([64, 3, 64, 64])\n",
      "539 torch.Size([64, 3, 64, 64])\n",
      "540 torch.Size([64, 3, 64, 64])\n",
      "541 torch.Size([64, 3, 64, 64])\n",
      "542 torch.Size([64, 3, 64, 64])\n",
      "543 torch.Size([64, 3, 64, 64])\n",
      "544 torch.Size([64, 3, 64, 64])\n",
      "545 torch.Size([64, 3, 64, 64])\n",
      "546 torch.Size([64, 3, 64, 64])\n",
      "547 torch.Size([64, 3, 64, 64])\n",
      "548 torch.Size([64, 3, 64, 64])\n",
      "549 torch.Size([64, 3, 64, 64])\n",
      "550 torch.Size([64, 3, 64, 64])\n",
      "551 torch.Size([64, 3, 64, 64])\n",
      "552 torch.Size([64, 3, 64, 64])\n",
      "553 torch.Size([64, 3, 64, 64])\n",
      "554 torch.Size([64, 3, 64, 64])\n",
      "555 torch.Size([64, 3, 64, 64])\n",
      "556 torch.Size([64, 3, 64, 64])\n",
      "557 torch.Size([64, 3, 64, 64])\n",
      "558 torch.Size([64, 3, 64, 64])\n",
      "559 torch.Size([64, 3, 64, 64])\n",
      "560 torch.Size([64, 3, 64, 64])\n",
      "561 torch.Size([64, 3, 64, 64])\n",
      "562 torch.Size([64, 3, 64, 64])\n",
      "563 torch.Size([64, 3, 64, 64])\n",
      "564 torch.Size([64, 3, 64, 64])\n",
      "565 torch.Size([64, 3, 64, 64])\n",
      "566 torch.Size([64, 3, 64, 64])\n",
      "567 torch.Size([64, 3, 64, 64])\n",
      "568 torch.Size([64, 3, 64, 64])\n",
      "569 torch.Size([64, 3, 64, 64])\n",
      "570 torch.Size([64, 3, 64, 64])\n",
      "571 torch.Size([64, 3, 64, 64])\n",
      "572 torch.Size([64, 3, 64, 64])\n",
      "573 torch.Size([64, 3, 64, 64])\n",
      "574 torch.Size([64, 3, 64, 64])\n",
      "575 torch.Size([64, 3, 64, 64])\n",
      "576 torch.Size([64, 3, 64, 64])\n",
      "577 torch.Size([64, 3, 64, 64])\n",
      "578 torch.Size([64, 3, 64, 64])\n",
      "579 torch.Size([64, 3, 64, 64])\n",
      "580 torch.Size([64, 3, 64, 64])\n",
      "581 torch.Size([64, 3, 64, 64])\n",
      "582 torch.Size([64, 3, 64, 64])\n",
      "583 torch.Size([64, 3, 64, 64])\n",
      "584 torch.Size([64, 3, 64, 64])\n",
      "585 torch.Size([64, 3, 64, 64])\n",
      "586 torch.Size([64, 3, 64, 64])\n",
      "587 torch.Size([64, 3, 64, 64])\n",
      "588 torch.Size([64, 3, 64, 64])\n",
      "589 torch.Size([64, 3, 64, 64])\n",
      "590 torch.Size([64, 3, 64, 64])\n",
      "591 torch.Size([64, 3, 64, 64])\n",
      "592 torch.Size([64, 3, 64, 64])\n",
      "593 torch.Size([64, 3, 64, 64])\n",
      "594 torch.Size([64, 3, 64, 64])\n",
      "595 torch.Size([64, 3, 64, 64])\n",
      "596 torch.Size([64, 3, 64, 64])\n",
      "597 torch.Size([64, 3, 64, 64])\n",
      "598 torch.Size([64, 3, 64, 64])\n",
      "599 torch.Size([64, 3, 64, 64])\n",
      "600 torch.Size([64, 3, 64, 64])\n",
      "601 torch.Size([64, 3, 64, 64])\n",
      "602 torch.Size([64, 3, 64, 64])\n",
      "603 torch.Size([64, 3, 64, 64])\n",
      "604 torch.Size([64, 3, 64, 64])\n",
      "605 torch.Size([64, 3, 64, 64])\n",
      "606 torch.Size([64, 3, 64, 64])\n",
      "607 torch.Size([64, 3, 64, 64])\n",
      "608 torch.Size([64, 3, 64, 64])\n",
      "609 torch.Size([64, 3, 64, 64])\n",
      "610 torch.Size([64, 3, 64, 64])\n",
      "611 torch.Size([64, 3, 64, 64])\n",
      "612 torch.Size([64, 3, 64, 64])\n",
      "613 torch.Size([64, 3, 64, 64])\n",
      "614 torch.Size([64, 3, 64, 64])\n",
      "615 torch.Size([64, 3, 64, 64])\n",
      "616 torch.Size([64, 3, 64, 64])\n",
      "617 torch.Size([64, 3, 64, 64])\n",
      "618 torch.Size([64, 3, 64, 64])\n",
      "619 torch.Size([64, 3, 64, 64])\n",
      "620 torch.Size([64, 3, 64, 64])\n",
      "621 torch.Size([64, 3, 64, 64])\n",
      "622 torch.Size([64, 3, 64, 64])\n",
      "623 torch.Size([64, 3, 64, 64])\n",
      "624 torch.Size([64, 3, 64, 64])\n",
      "625 torch.Size([64, 3, 64, 64])\n",
      "626 torch.Size([64, 3, 64, 64])\n",
      "627 torch.Size([64, 3, 64, 64])\n",
      "628 torch.Size([64, 3, 64, 64])\n",
      "629 torch.Size([64, 3, 64, 64])\n",
      "630 torch.Size([64, 3, 64, 64])\n",
      "631 torch.Size([64, 3, 64, 64])\n",
      "632 torch.Size([64, 3, 64, 64])\n",
      "633 torch.Size([64, 3, 64, 64])\n",
      "634 torch.Size([64, 3, 64, 64])\n",
      "635 torch.Size([64, 3, 64, 64])\n",
      "636 torch.Size([64, 3, 64, 64])\n",
      "637 torch.Size([64, 3, 64, 64])\n",
      "638 torch.Size([64, 3, 64, 64])\n",
      "639 torch.Size([64, 3, 64, 64])\n",
      "640 torch.Size([64, 3, 64, 64])\n",
      "641 torch.Size([64, 3, 64, 64])\n",
      "642 torch.Size([64, 3, 64, 64])\n",
      "643 torch.Size([64, 3, 64, 64])\n",
      "644 torch.Size([64, 3, 64, 64])\n",
      "645 torch.Size([64, 3, 64, 64])\n",
      "646 torch.Size([64, 3, 64, 64])\n",
      "647 torch.Size([64, 3, 64, 64])\n",
      "648 torch.Size([64, 3, 64, 64])\n",
      "649 torch.Size([64, 3, 64, 64])\n",
      "650 torch.Size([64, 3, 64, 64])\n",
      "651 torch.Size([64, 3, 64, 64])\n",
      "652 torch.Size([64, 3, 64, 64])\n",
      "653 torch.Size([64, 3, 64, 64])\n",
      "654 torch.Size([64, 3, 64, 64])\n",
      "655 torch.Size([64, 3, 64, 64])\n",
      "656 torch.Size([64, 3, 64, 64])\n",
      "657 torch.Size([64, 3, 64, 64])\n",
      "658 torch.Size([64, 3, 64, 64])\n",
      "659 torch.Size([64, 3, 64, 64])\n",
      "660 torch.Size([64, 3, 64, 64])\n",
      "661 torch.Size([64, 3, 64, 64])\n",
      "662 torch.Size([64, 3, 64, 64])\n",
      "663 torch.Size([64, 3, 64, 64])\n",
      "664 torch.Size([64, 3, 64, 64])\n",
      "665 torch.Size([64, 3, 64, 64])\n",
      "666 torch.Size([64, 3, 64, 64])\n",
      "667 torch.Size([64, 3, 64, 64])\n",
      "668 torch.Size([64, 3, 64, 64])\n",
      "669 torch.Size([64, 3, 64, 64])\n",
      "670 torch.Size([64, 3, 64, 64])\n",
      "671 torch.Size([64, 3, 64, 64])\n",
      "672 torch.Size([64, 3, 64, 64])\n",
      "673 torch.Size([64, 3, 64, 64])\n",
      "674 torch.Size([64, 3, 64, 64])\n",
      "675 torch.Size([64, 3, 64, 64])\n",
      "676 torch.Size([64, 3, 64, 64])\n",
      "677 torch.Size([64, 3, 64, 64])\n",
      "678 torch.Size([64, 3, 64, 64])\n",
      "679 torch.Size([64, 3, 64, 64])\n",
      "680 torch.Size([64, 3, 64, 64])\n",
      "681 torch.Size([64, 3, 64, 64])\n",
      "682 torch.Size([64, 3, 64, 64])\n",
      "683 torch.Size([64, 3, 64, 64])\n",
      "684 torch.Size([64, 3, 64, 64])\n",
      "685 torch.Size([64, 3, 64, 64])\n",
      "686 torch.Size([64, 3, 64, 64])\n",
      "687 torch.Size([64, 3, 64, 64])\n",
      "688 torch.Size([64, 3, 64, 64])\n",
      "689 torch.Size([64, 3, 64, 64])\n",
      "690 torch.Size([64, 3, 64, 64])\n",
      "691 torch.Size([64, 3, 64, 64])\n",
      "692 torch.Size([64, 3, 64, 64])\n",
      "693 torch.Size([64, 3, 64, 64])\n",
      "694 torch.Size([64, 3, 64, 64])\n",
      "695 torch.Size([64, 3, 64, 64])\n",
      "696 torch.Size([64, 3, 64, 64])\n",
      "697 torch.Size([64, 3, 64, 64])\n",
      "698 torch.Size([64, 3, 64, 64])\n",
      "699 torch.Size([64, 3, 64, 64])\n",
      "700 torch.Size([64, 3, 64, 64])\n",
      "701 torch.Size([64, 3, 64, 64])\n",
      "702 torch.Size([64, 3, 64, 64])\n",
      "703 torch.Size([64, 3, 64, 64])\n",
      "704 torch.Size([64, 3, 64, 64])\n",
      "705 torch.Size([64, 3, 64, 64])\n",
      "706 torch.Size([64, 3, 64, 64])\n",
      "707 torch.Size([64, 3, 64, 64])\n",
      "708 torch.Size([64, 3, 64, 64])\n",
      "709 torch.Size([64, 3, 64, 64])\n",
      "710 torch.Size([64, 3, 64, 64])\n",
      "711 torch.Size([64, 3, 64, 64])\n",
      "712 torch.Size([64, 3, 64, 64])\n",
      "713 torch.Size([64, 3, 64, 64])\n",
      "714 torch.Size([64, 3, 64, 64])\n",
      "715 torch.Size([64, 3, 64, 64])\n",
      "716 torch.Size([64, 3, 64, 64])\n",
      "717 torch.Size([64, 3, 64, 64])\n",
      "718 torch.Size([64, 3, 64, 64])\n",
      "719 torch.Size([64, 3, 64, 64])\n",
      "720 torch.Size([64, 3, 64, 64])\n",
      "721 torch.Size([64, 3, 64, 64])\n",
      "722 torch.Size([64, 3, 64, 64])\n",
      "723 torch.Size([64, 3, 64, 64])\n",
      "724 torch.Size([64, 3, 64, 64])\n",
      "725 torch.Size([64, 3, 64, 64])\n",
      "726 torch.Size([64, 3, 64, 64])\n",
      "727 torch.Size([64, 3, 64, 64])\n",
      "728 torch.Size([64, 3, 64, 64])\n",
      "729 torch.Size([64, 3, 64, 64])\n",
      "730 torch.Size([64, 3, 64, 64])\n",
      "731 torch.Size([64, 3, 64, 64])\n",
      "732 torch.Size([64, 3, 64, 64])\n",
      "733 torch.Size([64, 3, 64, 64])\n",
      "734 torch.Size([64, 3, 64, 64])\n",
      "735 torch.Size([64, 3, 64, 64])\n",
      "736 torch.Size([64, 3, 64, 64])\n",
      "737 torch.Size([64, 3, 64, 64])\n",
      "738 torch.Size([64, 3, 64, 64])\n",
      "739 torch.Size([64, 3, 64, 64])\n",
      "740 torch.Size([64, 3, 64, 64])\n",
      "741 torch.Size([64, 3, 64, 64])\n",
      "742 torch.Size([64, 3, 64, 64])\n",
      "743 torch.Size([64, 3, 64, 64])\n",
      "744 torch.Size([64, 3, 64, 64])\n",
      "745 torch.Size([64, 3, 64, 64])\n",
      "746 torch.Size([64, 3, 64, 64])\n",
      "747 torch.Size([64, 3, 64, 64])\n",
      "748 torch.Size([64, 3, 64, 64])\n",
      "749 torch.Size([64, 3, 64, 64])\n",
      "750 torch.Size([64, 3, 64, 64])\n",
      "751 torch.Size([64, 3, 64, 64])\n",
      "752 torch.Size([64, 3, 64, 64])\n",
      "753 torch.Size([64, 3, 64, 64])\n",
      "754 torch.Size([64, 3, 64, 64])\n",
      "755 torch.Size([64, 3, 64, 64])\n",
      "756 torch.Size([64, 3, 64, 64])\n",
      "757 torch.Size([64, 3, 64, 64])\n",
      "758 torch.Size([64, 3, 64, 64])\n",
      "759 torch.Size([64, 3, 64, 64])\n",
      "760 torch.Size([64, 3, 64, 64])\n",
      "761 torch.Size([64, 3, 64, 64])\n",
      "762 torch.Size([64, 3, 64, 64])\n",
      "763 torch.Size([64, 3, 64, 64])\n",
      "764 torch.Size([64, 3, 64, 64])\n",
      "765 torch.Size([64, 3, 64, 64])\n",
      "766 torch.Size([64, 3, 64, 64])\n",
      "767 torch.Size([64, 3, 64, 64])\n",
      "768 torch.Size([64, 3, 64, 64])\n",
      "769 torch.Size([64, 3, 64, 64])\n",
      "770 torch.Size([64, 3, 64, 64])\n",
      "771 torch.Size([64, 3, 64, 64])\n",
      "772 torch.Size([64, 3, 64, 64])\n",
      "773 torch.Size([64, 3, 64, 64])\n",
      "774 torch.Size([64, 3, 64, 64])\n",
      "775 torch.Size([64, 3, 64, 64])\n",
      "776 torch.Size([64, 3, 64, 64])\n",
      "777 torch.Size([64, 3, 64, 64])\n",
      "778 torch.Size([64, 3, 64, 64])\n",
      "779 torch.Size([64, 3, 64, 64])\n",
      "780 torch.Size([64, 3, 64, 64])\n",
      "781 torch.Size([64, 3, 64, 64])\n",
      "782 torch.Size([64, 3, 64, 64])\n",
      "783 torch.Size([64, 3, 64, 64])\n",
      "784 torch.Size([64, 3, 64, 64])\n",
      "785 torch.Size([64, 3, 64, 64])\n",
      "786 torch.Size([64, 3, 64, 64])\n",
      "787 torch.Size([64, 3, 64, 64])\n",
      "788 torch.Size([64, 3, 64, 64])\n",
      "789 torch.Size([64, 3, 64, 64])\n",
      "790 torch.Size([64, 3, 64, 64])\n",
      "791 torch.Size([64, 3, 64, 64])\n",
      "792 torch.Size([64, 3, 64, 64])\n",
      "793 torch.Size([64, 3, 64, 64])\n",
      "794 torch.Size([64, 3, 64, 64])\n",
      "795 torch.Size([64, 3, 64, 64])\n",
      "796 torch.Size([64, 3, 64, 64])\n",
      "797 torch.Size([64, 3, 64, 64])\n",
      "798 torch.Size([64, 3, 64, 64])\n",
      "799 torch.Size([64, 3, 64, 64])\n",
      "800 torch.Size([64, 3, 64, 64])\n",
      "801 torch.Size([64, 3, 64, 64])\n",
      "802 torch.Size([64, 3, 64, 64])\n",
      "803 torch.Size([64, 3, 64, 64])\n",
      "804 torch.Size([64, 3, 64, 64])\n",
      "805 torch.Size([64, 3, 64, 64])\n",
      "806 torch.Size([64, 3, 64, 64])\n",
      "807 torch.Size([64, 3, 64, 64])\n",
      "808 torch.Size([64, 3, 64, 64])\n",
      "809 torch.Size([64, 3, 64, 64])\n",
      "810 torch.Size([64, 3, 64, 64])\n",
      "811 torch.Size([64, 3, 64, 64])\n",
      "812 torch.Size([64, 3, 64, 64])\n",
      "813 torch.Size([64, 3, 64, 64])\n",
      "814 torch.Size([64, 3, 64, 64])\n",
      "815 torch.Size([64, 3, 64, 64])\n",
      "816 torch.Size([64, 3, 64, 64])\n",
      "817 torch.Size([64, 3, 64, 64])\n",
      "818 torch.Size([64, 3, 64, 64])\n",
      "819 torch.Size([64, 3, 64, 64])\n",
      "820 torch.Size([64, 3, 64, 64])\n",
      "821 torch.Size([64, 3, 64, 64])\n",
      "822 torch.Size([64, 3, 64, 64])\n",
      "823 torch.Size([64, 3, 64, 64])\n",
      "824 torch.Size([64, 3, 64, 64])\n",
      "825 torch.Size([64, 3, 64, 64])\n",
      "826 torch.Size([64, 3, 64, 64])\n",
      "827 torch.Size([64, 3, 64, 64])\n",
      "828 torch.Size([64, 3, 64, 64])\n",
      "829 torch.Size([64, 3, 64, 64])\n",
      "830 torch.Size([64, 3, 64, 64])\n",
      "831 torch.Size([64, 3, 64, 64])\n",
      "832 torch.Size([64, 3, 64, 64])\n",
      "833 torch.Size([64, 3, 64, 64])\n",
      "834 torch.Size([64, 3, 64, 64])\n",
      "835 torch.Size([64, 3, 64, 64])\n",
      "836 torch.Size([64, 3, 64, 64])\n",
      "837 torch.Size([64, 3, 64, 64])\n",
      "838 torch.Size([64, 3, 64, 64])\n",
      "839 torch.Size([64, 3, 64, 64])\n",
      "840 torch.Size([64, 3, 64, 64])\n",
      "841 torch.Size([64, 3, 64, 64])\n",
      "842 torch.Size([64, 3, 64, 64])\n",
      "843 torch.Size([64, 3, 64, 64])\n",
      "844 torch.Size([64, 3, 64, 64])\n",
      "845 torch.Size([64, 3, 64, 64])\n",
      "846 torch.Size([64, 3, 64, 64])\n",
      "847 torch.Size([64, 3, 64, 64])\n",
      "848 torch.Size([64, 3, 64, 64])\n",
      "849 torch.Size([64, 3, 64, 64])\n",
      "850 torch.Size([64, 3, 64, 64])\n",
      "851 torch.Size([64, 3, 64, 64])\n",
      "852 torch.Size([64, 3, 64, 64])\n",
      "853 torch.Size([64, 3, 64, 64])\n",
      "854 torch.Size([64, 3, 64, 64])\n",
      "855 torch.Size([64, 3, 64, 64])\n",
      "856 torch.Size([64, 3, 64, 64])\n",
      "857 torch.Size([64, 3, 64, 64])\n",
      "858 torch.Size([64, 3, 64, 64])\n",
      "859 torch.Size([64, 3, 64, 64])\n",
      "860 torch.Size([64, 3, 64, 64])\n",
      "861 torch.Size([64, 3, 64, 64])\n",
      "862 torch.Size([64, 3, 64, 64])\n",
      "863 torch.Size([64, 3, 64, 64])\n",
      "864 torch.Size([64, 3, 64, 64])\n",
      "865 torch.Size([64, 3, 64, 64])\n",
      "866 torch.Size([64, 3, 64, 64])\n",
      "867 torch.Size([64, 3, 64, 64])\n",
      "868 torch.Size([64, 3, 64, 64])\n",
      "869 torch.Size([64, 3, 64, 64])\n",
      "870 torch.Size([64, 3, 64, 64])\n",
      "871 torch.Size([64, 3, 64, 64])\n",
      "872 torch.Size([64, 3, 64, 64])\n",
      "873 torch.Size([64, 3, 64, 64])\n",
      "874 torch.Size([64, 3, 64, 64])\n",
      "875 torch.Size([64, 3, 64, 64])\n",
      "876 torch.Size([64, 3, 64, 64])\n",
      "877 torch.Size([64, 3, 64, 64])\n",
      "878 torch.Size([64, 3, 64, 64])\n",
      "879 torch.Size([64, 3, 64, 64])\n",
      "880 torch.Size([64, 3, 64, 64])\n",
      "881 torch.Size([64, 3, 64, 64])\n",
      "882 torch.Size([64, 3, 64, 64])\n",
      "883 torch.Size([64, 3, 64, 64])\n",
      "884 torch.Size([64, 3, 64, 64])\n",
      "885 torch.Size([64, 3, 64, 64])\n",
      "886 torch.Size([64, 3, 64, 64])\n",
      "887 torch.Size([64, 3, 64, 64])\n",
      "888 torch.Size([64, 3, 64, 64])\n",
      "889 torch.Size([64, 3, 64, 64])\n",
      "890 torch.Size([64, 3, 64, 64])\n",
      "891 torch.Size([64, 3, 64, 64])\n",
      "892 torch.Size([64, 3, 64, 64])\n",
      "893 torch.Size([64, 3, 64, 64])\n",
      "894 torch.Size([64, 3, 64, 64])\n",
      "895 torch.Size([64, 3, 64, 64])\n",
      "896 torch.Size([64, 3, 64, 64])\n",
      "897 torch.Size([64, 3, 64, 64])\n",
      "898 torch.Size([64, 3, 64, 64])\n",
      "899 torch.Size([64, 3, 64, 64])\n",
      "900 torch.Size([64, 3, 64, 64])\n",
      "901 torch.Size([64, 3, 64, 64])\n",
      "902 torch.Size([64, 3, 64, 64])\n",
      "903 torch.Size([64, 3, 64, 64])\n",
      "904 torch.Size([64, 3, 64, 64])\n",
      "905 torch.Size([64, 3, 64, 64])\n",
      "906 torch.Size([64, 3, 64, 64])\n",
      "907 torch.Size([64, 3, 64, 64])\n",
      "908 torch.Size([64, 3, 64, 64])\n",
      "909 torch.Size([64, 3, 64, 64])\n",
      "910 torch.Size([64, 3, 64, 64])\n",
      "911 torch.Size([64, 3, 64, 64])\n",
      "912 torch.Size([64, 3, 64, 64])\n",
      "913 torch.Size([64, 3, 64, 64])\n",
      "914 torch.Size([64, 3, 64, 64])\n",
      "915 torch.Size([64, 3, 64, 64])\n",
      "916 torch.Size([64, 3, 64, 64])\n",
      "917 torch.Size([64, 3, 64, 64])\n",
      "918 torch.Size([64, 3, 64, 64])\n",
      "919 torch.Size([64, 3, 64, 64])\n",
      "920 torch.Size([64, 3, 64, 64])\n",
      "921 torch.Size([64, 3, 64, 64])\n",
      "922 torch.Size([64, 3, 64, 64])\n",
      "923 torch.Size([64, 3, 64, 64])\n",
      "924 torch.Size([64, 3, 64, 64])\n",
      "925 torch.Size([64, 3, 64, 64])\n",
      "926 torch.Size([64, 3, 64, 64])\n",
      "927 torch.Size([64, 3, 64, 64])\n",
      "928 torch.Size([64, 3, 64, 64])\n",
      "929 torch.Size([64, 3, 64, 64])\n",
      "930 torch.Size([64, 3, 64, 64])\n",
      "931 torch.Size([64, 3, 64, 64])\n",
      "932 torch.Size([64, 3, 64, 64])\n",
      "933 torch.Size([64, 3, 64, 64])\n",
      "934 torch.Size([64, 3, 64, 64])\n",
      "935 torch.Size([64, 3, 64, 64])\n",
      "936 torch.Size([64, 3, 64, 64])\n",
      "937 torch.Size([64, 3, 64, 64])\n",
      "938 torch.Size([64, 3, 64, 64])\n",
      "939 torch.Size([64, 3, 64, 64])\n",
      "940 torch.Size([64, 3, 64, 64])\n",
      "941 torch.Size([64, 3, 64, 64])\n",
      "942 torch.Size([64, 3, 64, 64])\n",
      "943 torch.Size([64, 3, 64, 64])\n",
      "944 torch.Size([64, 3, 64, 64])\n",
      "945 torch.Size([64, 3, 64, 64])\n",
      "946 torch.Size([64, 3, 64, 64])\n",
      "947 torch.Size([64, 3, 64, 64])\n",
      "948 torch.Size([64, 3, 64, 64])\n",
      "949 torch.Size([64, 3, 64, 64])\n",
      "950 torch.Size([64, 3, 64, 64])\n",
      "951 torch.Size([64, 3, 64, 64])\n",
      "952 torch.Size([64, 3, 64, 64])\n",
      "953 torch.Size([64, 3, 64, 64])\n",
      "954 torch.Size([64, 3, 64, 64])\n",
      "955 torch.Size([64, 3, 64, 64])\n",
      "956 torch.Size([64, 3, 64, 64])\n",
      "957 torch.Size([64, 3, 64, 64])\n",
      "958 torch.Size([64, 3, 64, 64])\n",
      "959 torch.Size([64, 3, 64, 64])\n",
      "960 torch.Size([64, 3, 64, 64])\n",
      "961 torch.Size([64, 3, 64, 64])\n",
      "962 torch.Size([64, 3, 64, 64])\n",
      "963 torch.Size([64, 3, 64, 64])\n",
      "964 torch.Size([64, 3, 64, 64])\n",
      "965 torch.Size([64, 3, 64, 64])\n",
      "966 torch.Size([64, 3, 64, 64])\n",
      "967 torch.Size([64, 3, 64, 64])\n",
      "968 torch.Size([64, 3, 64, 64])\n",
      "969 torch.Size([64, 3, 64, 64])\n",
      "970 torch.Size([64, 3, 64, 64])\n",
      "971 torch.Size([64, 3, 64, 64])\n",
      "972 torch.Size([64, 3, 64, 64])\n",
      "973 torch.Size([64, 3, 64, 64])\n",
      "974 torch.Size([64, 3, 64, 64])\n",
      "975 torch.Size([64, 3, 64, 64])\n",
      "976 torch.Size([64, 3, 64, 64])\n",
      "977 torch.Size([64, 3, 64, 64])\n",
      "978 torch.Size([64, 3, 64, 64])\n",
      "979 torch.Size([64, 3, 64, 64])\n",
      "980 torch.Size([64, 3, 64, 64])\n",
      "981 torch.Size([64, 3, 64, 64])\n",
      "982 torch.Size([64, 3, 64, 64])\n",
      "983 torch.Size([64, 3, 64, 64])\n",
      "984 torch.Size([64, 3, 64, 64])\n",
      "985 torch.Size([64, 3, 64, 64])\n",
      "986 torch.Size([64, 3, 64, 64])\n",
      "987 torch.Size([64, 3, 64, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TinyImageNet(ds, transforms\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor())\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader) :\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[61], line 10\u001b[0m, in \u001b[0;36mTinyImageNet.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx) :\n\u001b[1;32m---> 10\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m :\n\u001b[0;32m     12\u001b[0m         ret \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(ret, repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2782\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2767\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2765\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2766\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2767\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2769\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:225\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py:2049\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2034\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2035\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2036\u001b[0m \n\u001b[0;32m   2037\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2049\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2050\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2052\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2053\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2054\u001b[0m         )\n\u001b[0;32m   2055\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py:1407\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\image.py:188\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 188\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mc:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = TinyImageNet(ds, transforms=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "\n",
    "for i, iter in enumerate(train_loader) :\n",
    "    print(i, iter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.56467"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optimagic as om\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def func(x) :\n",
    "    return math.tan(x)\n",
    "\n",
    "lbfgsb_res = om.maximize(\n",
    "    fun=func,\n",
    "    params=0,\n",
    "    algorithm=\"scipy_lbfgsb\",\n",
    ")\n",
    "lbfgsb_res.params.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 4.991182883662404e-10, 'y': -6.638553873283826e-10}\n",
      "\n",
      "Test 2 (continue) - Optimization completed with penalty values\n",
      "Final parameters: {'x': 4.991182883662404e-10, 'y': -6.638553873283826e-10}\n",
      "Final criterion value: 6.898230410665623e-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optimagic\\deprecations.py:31: FutureWarning: To align optimagic with scipy.optimize, the `criterion` argument has been renamed to `fun`. Please use `fun` instead of `criterion`. Using `criterion`  will become an error in optimagic version 0.6.0 and later.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optimagic\\deprecations.py:31: FutureWarning: To align optimagic with scipy.optimize, the `criterion` argument has been renamed to `fun`. Please use `fun` instead of `criterion`. Using `criterion`  will become an error in optimagic version 0.6.0 and later.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\Users\\azizs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optimagic\\optimization\\optimize_result.py:77: FutureWarning: The criterion attribute is deprecated. Use the fun attribute instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from optimagic import minimize\n",
    "# from optimagic import parameter_bounds\n",
    "\n",
    "def test_function(params):\n",
    "    \"\"\"A test function that produces infinite gradients at certain points.\"\"\"\n",
    "    x, y = params[\"x\"], params[\"y\"]\n",
    "    \n",
    "    # Function value\n",
    "    f = x**2 + y**2\n",
    "    \n",
    "    # Gradient with potential infinite values\n",
    "    # grad = {\n",
    "    #     \"x\": 2 * x,\n",
    "    #     \"y\": 2 * y / (y - 1)  # This will be infinite when y = 1\n",
    "    # }\n",
    "    \n",
    "    return f #, grad\n",
    "\n",
    "# Define parameters with bounds\n",
    "params = {\n",
    "    \"x\": 1.0,\n",
    "    \"y\": 0.5  # Start close to y=1 to trigger infinite gradient\n",
    "}\n",
    "\n",
    "# bounds = parameter_bounds(\n",
    "#     lower={\"x\": -10, \"y\": -10},\n",
    "#     upper={\"x\": 10, \"y\": 10}\n",
    "# )\n",
    "\n",
    "# Test 1: With error_handling=\"raise\" (should raise InvalidFunctionError)\n",
    "result = minimize(\n",
    "    criterion=test_function,\n",
    "    params=params,\n",
    "    algorithm=\"scipy_lbfgsb\",\n",
    "    # bounds=bounds,\n",
    "    error_handling=\"raise\"\n",
    ")\n",
    "\n",
    "print(result.params)\n",
    "\n",
    "# Test 2: With error_handling=\"continue\" (should use penalty values)\n",
    "result = minimize(\n",
    "    criterion=test_function,\n",
    "    params=params,\n",
    "    algorithm=\"scipy_lbfgsb\",\n",
    "    # bounds=bounds,\n",
    "    error_handling=\"continue\"\n",
    ")\n",
    "print(\"\\nTest 2 (continue) - Optimization completed with penalty values\")\n",
    "print(f\"Final parameters: {result.params}\")\n",
    "print(f\"Final criterion value: {result.criterion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((32, 16, 64, 64))\n",
    "patch_size = 4\n",
    "embed = get_2d_sincos_pos_embed(128, (x.shape[-1]//patch_size))\n",
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "dataset = torchvision.datasets.MNIST(root='data/', train=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNIST(torch.utils.data.Dataset) :\n",
    "    def __init__(self, root, train, transform) :\n",
    "        self.data = torchvision.datasets.MNIST(root=root, train=train, transform=transform)\n",
    "    def __len__(self) :\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        imgs, labels = self.data[idx]\n",
    "        return imgs.numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomMNIST(root='data/', train=True, transform=torchvision.transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=True)\n",
    "dataset = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]),\n",
       " torch.Tensor,\n",
       " tensor([1, 1, 1, 2, 0, 7, 0, 9, 1, 8, 3, 8, 5, 8, 5, 3, 2, 3, 1, 3, 4, 5, 0, 9,\n",
       "         8, 2, 4, 0, 8, 7, 1, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape, type(imgs), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shortcut_models.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiT: Input of shape (32, 16, 16, 64) dtype float32\n",
      "x (32, 16, 16, 64)\n",
      "DiT: After patch embed, shape is (32, 16, 128) dtype bfloat16\n",
      "DiT: Patch Embed of shape (32, 16, 128) dtype bfloat16\n",
      "DiT: Conditioning of shape (32, 128) dtype float32\n",
      "DiT: Input of shape (32, 16, 16, 64) dtype float32\n",
      "x (32, 16, 16, 64)\n",
      "DiT: After patch embed, shape is (32, 16, 128) dtype bfloat16\n",
      "DiT: Patch Embed of shape (32, 16, 128) dtype bfloat16\n",
      "DiT: Conditioning of shape (32, 128) dtype float32\n"
     ]
    }
   ],
   "source": [
    "# x = torch.randn((32,64,16,16))\n",
    "# model = DiT(patch_size=4, hidden_size=128, depth=4, num_heads=2, mlp_ratio=4, out_channels=16, class_dropout_prob=0., num_classes=10)\n",
    "\n",
    "# Instantiate the module\n",
    "model = DiT(patch_size=4, hidden_size=128, depth=4, num_heads=2, mlp_ratio=4, out_channels=16, class_dropout_prob=0., num_classes=10)\n",
    "\n",
    "# Initialize parameters\n",
    "key = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones((32,64,16,16))  # whatever input shape you need\n",
    "dummy_t = jnp.ones((32,))  # whatever input shape you need\n",
    "dummy_y = jnp.ones((32,), dtype='int32') # whatever input shape you need\n",
    "params = model.init(key, dummy_input, dummy_t, dummy_t, dummy_y)  # Binds the module\n",
    "\n",
    "# Apply the model\n",
    "output = model.apply(params, dummy_input, dummy_t, dummy_t, dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16, 16, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
